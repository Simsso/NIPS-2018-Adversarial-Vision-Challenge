{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny ImageNet Inception Transfer Learning\n",
    "\n",
    "## Goal\n",
    "Use a Inception v3 model pretrained on the full ImageNet in order to achieve >60% accuracy on the Tiny ImageNet validation set.\n",
    "\n",
    "## Approach\n",
    "1. Download a pretrained Inception v3 model\n",
    "2. Load the Tiny ImageNet training and validation datasets\n",
    "3. Cache the transfer values (second-last layer activations) for the whole Tiny ImageNet training and validation set\n",
    "4. Build the graph to take the feature extractions, apply one dense layer and one softmax classification layer\n",
    "5. Design a training algorithm and conduct hyperparameter search to push the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the Inception v3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Inception v3 Model ...\n",
      "- Download progress: 100.0%\n",
      "Download finished. Extracting files.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from model import inception\n",
    "inception.maybe_download()\n",
    "model = inception.Inception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Tiny ImageNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.tiny_imagenet as data\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Helper Functions to load all the images, not create a `tf.train.input_producer`-queue\n",
    "def load_image(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    return img\n",
    "\n",
    "def load_tiny_image_net(mode, limit=None):\n",
    "    filenames_labels = data.load_filenames_labels(mode)\n",
    "    # import: don't shuffle here, otherwise the cached transfer values will be useless!\n",
    "    if limit:\n",
    "        filenames_labels = filenames_labels[:limit]\n",
    "    images = np.array([load_image(img) for img, _ in filenames_labels])\n",
    "    labels = np.array([label for _, label in filenames_labels])\n",
    "    labels = labels.astype(np.uint8)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes about 1-2min (use the limit parameter if you're testing something and don't need to load everything)\n",
    "limit = 100 # None\n",
    "train_images, train_labels = load_tiny_image_net('train', limit=limit)\n",
    "val_images, val_labels = load_tiny_image_net('val', limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: images: (100, 64, 64, 3), labels: (100,)\n",
      "Validation Set: images: (100, 64, 64, 3), labels: (100,)\n"
     ]
    }
   ],
   "source": [
    "# check the shapes (should be 100,000 training and 10,000 validation images with dimensions 64x64x3)\n",
    "print(\"Training Set: images: {}, labels: {}\".format(train_images.shape, train_labels.shape))\n",
    "print(\"Validation Set: images: {}, labels: {}\".format(val_images.shape, val_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate and Cache the Transfer Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cache_dir = \"cache/tiny-imagenet/\"\n",
    "cache_path_train = os.path.join(cache_dir, \"inception_tiny_imagenet_train.pkl\")\n",
    "cache_path_val = os.path.join(cache_dir, \"inception_tiny_imagenet_val.pkl\")\n",
    "\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transfer values:\n",
      "- Data loaded from cache-file: cache/tiny-imagenet/inception_tiny_imagenet_train.pkl\n",
      "Validation transfer values:\n",
      "- Data loaded from cache-file: cache/tiny-imagenet/inception_tiny_imagenet_val.pkl\n"
     ]
    }
   ],
   "source": [
    "# this should be done on a fast, GPU-powered machine. TODO: process in batches!\n",
    "print(\"Training transfer values:\")\n",
    "transfer_values_train = inception.transfer_values_cache(cache_path=cache_path_train,\n",
    "                                                        images=train_images,\n",
    "                                                        model=model)\n",
    "print(\"Validation transfer values:\")\n",
    "transfer_values_val = inception.transfer_values_cache(cache_path=cache_path_val,\n",
    "                                                      images=val_images,\n",
    "                                                      model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set transfer values: (100, 2048)\n",
      "Validation Set transfer values: (100, 2048)\n"
     ]
    }
   ],
   "source": [
    "# check the shapes of the transfer values (should have 2048 transfer values (second channel))\n",
    "print(\"Training Set transfer values: {}\".format(transfer_values_train.shape))\n",
    "print(\"Validation Set transfer values: {}\".format(transfer_values_val.shape))\n",
    "\n",
    "_, transfer_len = transfer_values_train.shape # 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the Classification Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO weight decay (?)\n",
    "def model(x):\n",
    "    with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        # simple 2-layer graph\n",
    "        fc1 = tf.layers.dense(x, units=1024, name=\"classifier/fc1\")\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "        logits = tf.layers.dense(fc1, units=data.NUM_CLASSES, name=\"classifier/logits\")\n",
    "        softmax = tf.nn.softmax(logits, axis=1, name='softmax')\n",
    "    return logits, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):  # TODO weight decay\n",
    "    labels_one_hot = tf.one_hot(labels, depth=data.NUM_CLASSES)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels_one_hot, logits=logits)\n",
    "    loss = tf.reduce_mean(cross_entropy, name=\"classifier/cross_entropy_loss\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, softmax):\n",
    "    correct = tf.cast(tf.equal(tf.argmax(softmax, axis=1), tf.cast(labels, tf.int64)), dtype=tf.float32)\n",
    "    return tf.reduce_mean(correct, name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.002\n",
    "NUM_EPOCHS = 1000\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VALIDATION_BATCH_SIZE = 64\n",
    "STEPS_PER_EPOCH = min(data.NUM_TRAIN_SAMPLES // TRAIN_BATCH_SIZE, data.NUM_TRAIN_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimization_op(loss):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "    return optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    num_images = len(transfer_values_train)\n",
    "    # random index\n",
    "    idx = np.random.choice(num_images, size=TRAIN_BATCH_SIZE, replace=False)\n",
    "    x_batch = transfer_values_train[idx]\n",
    "    y_batch = train_labels[idx]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batch_size, x, y):\n",
    "    vals = []\n",
    "    total_count = len(y)\n",
    "    for i in range(min(total_count // batch_size, total_count)):\n",
    "        from_idx = i*batch_size\n",
    "        to_idx = (i+1)*batch_size\n",
    "        x_batch = x[from_idx:to_idx]\n",
    "        y_batch = y[from_idx:to_idx]\n",
    "        vals.append(sess.run([accuracy_val, loss_val], feed_dict={\n",
    "            features: x_batch,\n",
    "            labels: y_batch\n",
    "        }))\n",
    "    acc_mean, loss_mean = np.mean(vals, axis=0)\n",
    "    return acc_mean, loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # placeholders\n",
    "    features = tf.placeholder(tf.float32, shape=[None, transfer_len], name=\"transfer_features\")\n",
    "    labels = tf.placeholder(tf.uint8, shape=[None], name=\"labels\")\n",
    "    \n",
    "    # graph\n",
    "    logits, softmax = model(features)\n",
    "    loss_val = loss(labels, logits)\n",
    "    accuracy_val = accuracy(labels, softmax)\n",
    "    \n",
    "    optimizer = get_optimization_op(loss_val)\n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch #1\n",
      "Validation before: accuracy 0.0, loss 5.495240688323975\n",
      "Training: accuracy 0.9977793097496033, loss 0.013392413966357708\n",
      "Starting epoch #2\n",
      "Validation before: accuracy 0.0, loss 19.239974975585938\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-af40e9071a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             _, t_acc, t_loss = sess.run([optimizer, accuracy_val, loss_val], feed_dict={\n\u001b[1;32m     15\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_true_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             })\n\u001b[1;32m     18\u001b[0m             \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session(graph=graph)\n",
    "with sess.as_default():\n",
    "    sess.run(init)\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        print(\"Starting epoch #%d\" % (i + 1))\n",
    "        # show validation accuracy\n",
    "        val_acc, val_loss = evaluate(batch_size=VALIDATION_BATCH_SIZE, \n",
    "                                     x=transfer_values_val, y=val_labels)\n",
    "        print(\"Validation before: accuracy {}, loss {}\".format(val_acc, val_loss))\n",
    "        \n",
    "        vals = []\n",
    "        for _ in range(STEPS_PER_EPOCH):\n",
    "            x_batch, y_true_batch = random_batch()\n",
    "            _, t_acc, t_loss = sess.run([optimizer, accuracy_val, loss_val], feed_dict={\n",
    "                features: x_batch,\n",
    "                labels: y_true_batch\n",
    "            })\n",
    "            vals.append((t_acc, t_loss))\n",
    "        train_acc, train_loss = np.mean(vals, axis=0)\n",
    "        print(\"Training: accuracy {}, loss {}\".format(train_acc, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
